<!doctype html>
<html lang="en">

  <head>
    <meta charset="utf-8">

    <title>Scraping with Python</title>

    <meta name="description" content="A short presentation introducing the basics of web scraping with Python">
    <meta name="author" content="Nick Stenning">

    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <link rel="stylesheet" href="node_modules/reveal.js/css/reveal.min.css">
    <link rel="stylesheet" href="theme.css" id="theme">

    <!-- For syntax highlighting -->
    <link rel="stylesheet" href="node_modules/reveal.js/lib/css/zenburn.css">

    <!-- If the query includes 'print-pdf', include the PDF print sheet -->
    <script>
      if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'node_modules/reveal.js/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
      }
    </script>

    <!--[if lt IE 9]>
    <script src="node_modules/reveal.js/lib/js/html5shiv.js"></script>
    <![endif]-->
  </head>

  <body>

    <div class="reveal">

      <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">
        <section>
          <h2>Scraping with Python</h2>
          <p>
            A short introduction to the basics of scraping webpages with Python,
            by <a href="https://whiteink.com">Nick Stenning</a>
            (<a href="https://twitter.com/nickstenning">@nickstenning</a>).
          </p>
        </section>

        <section>
          <h2>Why?</h2>
          <p>I want to live in a houseboat.</p>
        </section>

        <section>
          <img src="img/crt.png" alt="A screenshot of the Canal and River Trust mooring auction website">
        </section>

        <section>
          <h2>Start with a problem</h2>
          <p>Are there any new mooring auctions that match my criteria?</p>
          <p class="fragment">
            How many rulings does the Federal Constitutional Court of Germany
            make each year?
          </p>
        </section>

        <section>
          <img src="img/bvg-decisions.png" alt="A screenshot of the Bundesverfassungsgericht website">
        </section>

        <section>
          <h2>Solutions</h2>
          <ol>
            <li>visit each page</li>
            <li>copy information into a spreadsheet</li>
            <li>review against criteria/analyse</li>
          </ol>
          <p>
            <br>
            We could do this all by hand&hellip; <em>or</em> we could use some
            kind of device that's really good at boring, repetitive drudge
            work...
          </p>
        </section>

        <section>
          <h2>Scraping</h2>
          <p>It sounds messy.</p>
          <p>It <strong>is</strong> messy.</p>
          <p class="fragment">But it can be beautiful.</p>
        </section>

        <section>
          <h2>Scraping steps</h2>
          <ol>
            <li>Extract</li>
            <li>Transform</li>
            <li>Load</li>
          </ol>
        </section>

        <section>
          <h2>Extract</h2>
          <pre><code class="python" data-trim>
import requests
import pyquery

# Extract
response = requests.get("https://www.crtmoorings.com/auctions/search.php")
document = pyquery.PyQuery(response.content)

# Transform
headings = document.find("h3.vacancy_summary")
for h in headings.items():
    print h.text()
          </code></pre>
          <pre class="fragment">
Auction: 6261 - Torksey Lock, Fossdyke Navigation
Auction: 6286 - Napton Bottom Lock, Oxford Canal
Auction: 6273 - Netherwich Basin, Droitwich Barge Canal
Auction: 5915 - Engineers Wharf Residential , Paddington Arm.
...
          </pre>
        </section>

        <section>
          <section>
            <h2>Transform</h2>
            <pre><code class="python" data-trim>
import requests
import pyquery

# Extract
response = requests.get("https://www.crtmoorings.com/auctions/search.php")
document = pyquery.PyQuery(response.content)

# Transform
prices = document.find(".vacancy_details + .vacancy_details p:nth-child(1)")
for p in prices.items():
    print p.text()
          </code></pre>
          <pre class="fragment">
Guide price: £821 inc VAT per year
Guide price: £1,857 inc VAT per year
Guide price: £649 inc VAT per year
Guide price: £5,880 inc VAT per year
...
          </pre>
          </section>

          <section>
            <h2>A trade secret</h2>
            <p><a href='http://selectorgadget.com/'>SelectorGadget</a></p>
            <img height="500" src="img/selectorgadget.gif" alt="An animated image showing SelectorGadget narrowing down a selection on a page">
          </section>
        </section>

        <section>
          <h2>Transform (II)</h2>
          <pre><code class="python" data-trim>
import json

import requests
import pyquery

...

# Extract
response = requests.get("https://www.crtmoorings.com/auctions/search.php")
document = pyquery.PyQuery(response.content)

# Transform
headings = document.find("h3.vacancy_summary")
for h in headings.items():
    mooring = get_mooring_details(h)
    print json.dumps(mooring, indent=2)
          </code></pre>
        </section>

        <section>
          <h2>Transform (III)</h2>
          <img src="img/inspector.png" alt="Screenshot showing use of Chrome web inspector to look at source code">
        </section>

        <section>
          <h2>Transform (IV)</h2>
          <pre><code class="python" data-trim>
def get_mooring_details(heading):
    details = heading.next()
    mooring = {}
    mooring["Title"] = heading.text()
    mooring["Image URL"] = details(".vacancy_main_img a img").attr("src")

    # For each paragraph element in the vacancy_details divs
    for d in details.find(".vacancy_details p").items():
        # If the paragraph element has a child "strong" element
        if d.find("strong").length > 0:
            # Split the text on the first colon
            key, val = d.text().split(":", 1)
            # Trim any whitespace
            key, val = key.strip(), val.strip()
            # Put the details in the dict
            mooring[key] = val

    return mooring
          </code></pre>
          <pre class="fragment">
    {
  "Number of online views": "176",
  "Maximum length": "18.5m / 60.70ft berth",
  "Title": "Auction: 6278 - Market Harborough Basin, Grand Union Canal",
  "Bids received": "0",
...
          </pre>
        </section>

        <section>
          <h2>Load</h2>
          <pre><code class="python" data-trim>
import dataset

...

engine = dataset.connect('sqlite:///moorings.db')
auctions = engine['auctions']

# Extract
response = requests.get("https://www.crtmoorings.com/auctions/search.php")
document = pyquery.PyQuery(response.content)

# Transform
headings = document.find("h3.vacancy_summary")
for h in headings.items():
    mooring = get_mooring_details(h)

    # Load
    auctions.insert(mooring)

# Confirm what we've got
print("%d rows in auctions table" % len(auctions))
          </code></pre>
        </section>

        <section>
          <h2>Idempotence</h2>
          <blockquote>
            <p>
            Idempotent (/i.dɨmˈpoʊtənt/ ih-dəm-poh-tənt)
            </p>
            <p>
              adj., describing an action which, when performed multiple times, has
              no further effect on its subject after the first time it is
              performed.
            </p>
          </blockquote>
        </section>

        <section>
          <h2>Idempotence (II)</h2>
          <p>
            You can make a scraping operation idempotent if you can tell if two
            things are the same as one another.
          </p>
          <p>
            Idempotence is usually about finding <em>unique identifiers</em>.
            <br>
            <br>
          </p>
          <pre class="fragment">
Auction: <strong style="color: #f00">6261</strong> - Torksey Lock, Fossdyke Navigation
Auction: <strong style="color: #f00">6286</strong> - Napton Bottom Lock, Oxford Canal
Auction: <strong style="color: #f00">6273</strong> - Netherwich Basin, Droitwich Barge Canal
...
          </pre>
        </section>

        <section>
          <h2>Load (II)</h2>
          <pre>
<code class="python faded" data-trim>
def get_mooring_details(heading):
    ...
</code></pre><pre><code class="python">
    id_match = re.match(r'Auction: (\d+)', mooring["Title"])
    mooring["id"] = int(id_match.group(1))

</code></pre><pre><code class="python faded">    return mooring

...

# Transform
headings = document.find("h3.vacancy_summary")
for h in headings.items():
    mooring = get_mooring_details(h)
</code></pre><pre><code class="python">
    # Load
    auctions.upsert(mooring, ["id"])

</code></pre><pre><code class="python faded" data-trim>
# Confirm what we've got
print("%d rows in auctions table" % len(auctions))
          </code></pre>
        </section>

        <section>
          <h2>Now what?</h2>
          <p>
            SPREADSHEETS.
          </p>
          <pre><code class="bash" data-trim>
sqlite3 -header -csv moorings.db 'select * from auctions;' &gt; auctions.csv
          </code></pre>
          <div class="fragment">
            <p>
              SIMPLER SPREADSHEETS.
            </p>
            <pre><code class="bash" data-trim>
datafreeze freezefile.yaml
            </code></pre>
            <pre class="fragment">
common:
  database: "sqlite:///moorings.db"
  prefix: dumps/
  format: csv
exports:
  - query: "SELECT id, Title, `Guide price` FROM auctions"
    filename: "auctions.csv"
  - query: "SELECT id, `Image URL` FROM auctions"
    filename: "images.csv"</pre>
          </div>
        </section>

        <section>
          <h2>In summary</h2>
          <ul>
            <li>Start with a problem</li>
            <li>Extract, Transform, Load</li>
            <li>Idempotence! (Find the unique identifiers)</li>
            <li>Lots of libraries to help you: <code>dataset</code>, <code>pyquery</code>, <code>requests</code></li>
          </ul>
        </section>

        <section>
          <h2>I haven't even mentioned...</h2>
          <ul>
            <li>Data types ("GBP35,292 inc VAT per year" is not a number!)</li>
            <li>Page navigation (<a href="http://wwwsearch.sourceforge.net/mechanize/"><code>mechanize</code></a>)</li>
            <li>Parallelism, AKA "multithreading" (<a href="https://github.com/pudo/thready"><code>thready</code></a>)</li>
          </ul>
        </section>

        <section>
          <h2>Resources</h2>
          <ul>
            <li><a href="http://docs.python-requests.org/en/latest/"><code>requests</code></a>: HTTP client (get page contents)</li>
            <li><a href="http://pythonhosted.org/pyquery/"><code>pyquery</code></a>: find stuff using CSS selectors (jQuery for Python)</li>
            <li><a href="https://dataset.readthedocs.org/en/latest/"><code>dataset</code></a>: shove stuff into a database without thinking</li>
            <li><a href="http://wwwsearch.sourceforge.net/mechanize/"><code>mechanize</code></a>: click on links, fill in forms</li>
            <li><a href="http://scrapy.org/"><code>scrapy</code></a>: everything!</li>
          </ul>
        </section>
      </div>
    </div>

    <script src="node_modules/reveal.js/lib/js/head.min.js"></script>
    <script src="node_modules/reveal.js/js/reveal.min.js"></script>

    <script>

      // Full list of configuration options available here:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,

        dependencies: [
          { src: 'node_modules/reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
        ]
      });

    </script>

  </body>
</html>
